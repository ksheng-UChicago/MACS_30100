{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46eed391",
   "metadata": {},
   "source": [
    "## Linear methods for regression and classification\n",
    "In this jupyter notebook, we will practice the topics covered in the lectures. Specially, we will do hands-on practice of:\n",
    "- load and prepare data for machine learning model training and testing\n",
    "- train and test linear models (linear regression (lasso/ridge), polynomial regression, and logistic regression)\n",
    "- compare and understand model performance \n",
    "\n",
    "For implementations that have fixed results, we provide running examples for your reference. *You might get slightly different results due to the sklearn version you are using, just leave a comment to indicate your version where you get different results.*<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5acb55f",
   "metadata": {},
   "source": [
    "## Linear Regression and Polynomial Regression\n",
    "In this section, we will explore the diabetes dataset:\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html#sklearn.datasets.load_diabetes <br>\n",
    "\n",
    "This dataset contains n = 442 diabetes patients' information of ten variables: age, sex, body mass index, average blood pressure, and six blood serum measurements. Each patient has a quantitative value of disease progression one year after baseline.\n",
    "\n",
    "\n",
    "We will fit different regression models to analyze this dataset: \n",
    "The steps include:\n",
    "1. Basic data exploration:\n",
    "    > what does the data look like (#samples, #features) <br>\n",
    "    > the feature matrix and description of each feature <br>\n",
    "    > the target variable <br>\n",
    "    \n",
    "2. Prepare data for model training and testing <br>\n",
    "\n",
    "3. Fit different regression models (linear/lasso/ridge) on the training set and evaluate model performance on the testing set <br>\n",
    "\n",
    "4. Compare and understand model performance through interpreting coefficients.\n",
    "\n",
    "**Note:** please always add comments to explain your observations/findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "eab86d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "6253bf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "36fb790a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are different ways to load the dataset, please make sure you understand the mechanism\n",
    "# reference: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html\n",
    "data = load_diabetes(as_frame=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db355e95",
   "metadata": {},
   "source": [
    "### Basic dataset exploration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "94e585c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((442, 10), (442,))"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data.shape, data.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "83f34331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "abcc0287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019907</td>\n",
       "      <td>-0.017646</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068332</td>\n",
       "      <td>-0.092204</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005670</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022688</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031988</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.019662</td>\n",
       "      <td>0.059744</td>\n",
       "      <td>-0.005697</td>\n",
       "      <td>-0.002566</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.031193</td>\n",
       "      <td>0.007207</td>\n",
       "      <td>178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>-0.005515</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>-0.067642</td>\n",
       "      <td>0.049341</td>\n",
       "      <td>0.079165</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>-0.018114</td>\n",
       "      <td>0.044485</td>\n",
       "      <td>104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>0.017293</td>\n",
       "      <td>-0.037344</td>\n",
       "      <td>-0.013840</td>\n",
       "      <td>-0.024993</td>\n",
       "      <td>-0.011080</td>\n",
       "      <td>-0.046883</td>\n",
       "      <td>0.015491</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.016318</td>\n",
       "      <td>0.015283</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.026560</td>\n",
       "      <td>0.044529</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.073030</td>\n",
       "      <td>-0.081413</td>\n",
       "      <td>0.083740</td>\n",
       "      <td>0.027809</td>\n",
       "      <td>0.173816</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.004222</td>\n",
       "      <td>0.003064</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>442 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0    0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1   -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2    0.085299  0.050680  0.044451 -0.005670 -0.045599 -0.034194 -0.032356   \n",
       "3   -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4    0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "437  0.041708  0.050680  0.019662  0.059744 -0.005697 -0.002566 -0.028674   \n",
       "438 -0.005515  0.050680 -0.015906 -0.067642  0.049341  0.079165 -0.028674   \n",
       "439  0.041708  0.050680 -0.015906  0.017293 -0.037344 -0.013840 -0.024993   \n",
       "440 -0.045472 -0.044642  0.039062  0.001215  0.016318  0.015283 -0.028674   \n",
       "441 -0.045472 -0.044642 -0.073030 -0.081413  0.083740  0.027809  0.173816   \n",
       "\n",
       "           s4        s5        s6  target  \n",
       "0   -0.002592  0.019907 -0.017646   151.0  \n",
       "1   -0.039493 -0.068332 -0.092204    75.0  \n",
       "2   -0.002592  0.002861 -0.025930   141.0  \n",
       "3    0.034309  0.022688 -0.009362   206.0  \n",
       "4   -0.002592 -0.031988 -0.046641   135.0  \n",
       "..        ...       ...       ...     ...  \n",
       "437 -0.002592  0.031193  0.007207   178.0  \n",
       "438  0.034309 -0.018114  0.044485   104.0  \n",
       "439 -0.011080 -0.046883  0.015491   132.0  \n",
       "440  0.026560  0.044529 -0.025930   220.0  \n",
       "441 -0.039493 -0.004222  0.003064    57.0  \n",
       "\n",
       "[442 rows x 11 columns]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "8fe381e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>152.133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>77.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>-0.127</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>-0.138</td>\n",
       "      <td>25.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.037</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>87.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>140.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.038</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.028</td>\n",
       "      <td>211.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.111</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.136</td>\n",
       "      <td>346.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           age      sex      bmi       bp       s1       s2       s3       s4  \\\n",
       "count  442.000  442.000  442.000  442.000  442.000  442.000  442.000  442.000   \n",
       "mean    -0.000    0.000   -0.000   -0.000   -0.000    0.000   -0.000   -0.000   \n",
       "std      0.048    0.048    0.048    0.048    0.048    0.048    0.048    0.048   \n",
       "min     -0.107   -0.045   -0.090   -0.112   -0.127   -0.116   -0.102   -0.076   \n",
       "25%     -0.037   -0.045   -0.034   -0.037   -0.034   -0.030   -0.035   -0.039   \n",
       "50%      0.005   -0.045   -0.007   -0.006   -0.004   -0.004   -0.007   -0.003   \n",
       "75%      0.038    0.051    0.031    0.036    0.028    0.030    0.029    0.034   \n",
       "max      0.111    0.051    0.171    0.132    0.154    0.199    0.181    0.185   \n",
       "\n",
       "            s5       s6   target  \n",
       "count  442.000  442.000  442.000  \n",
       "mean     0.000    0.000  152.133  \n",
       "std      0.048    0.048   77.093  \n",
       "min     -0.126   -0.138   25.000  \n",
       "25%     -0.033   -0.033   87.000  \n",
       "50%     -0.002   -0.001  140.500  \n",
       "75%      0.032    0.028  211.500  \n",
       "max      0.134    0.136  346.000  "
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(data.frame.describe(),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "5b3e48c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot a histogram to visualize the distribution of the \"target\" value\n",
    "plt.hist(data.frame['target'], rwidth=0.9)\n",
    "plt.title(\"Target value distribution\")\n",
    "plt.xlabel(\"target value\")\n",
    "plt.ylabel(\"#samples\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0964e70",
   "metadata": {},
   "source": [
    "### Prepare data for model training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "73f1b21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into 70% training and 30% testing\n",
    "# Documentation: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "# Remember to set random_state to control for the randomness\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "5172c982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((309, 10), (133, 10))"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check feature matrix\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a796cd9b",
   "metadata": {},
   "source": [
    "### Fit the linear regression model on the training set and evaluate model performance on the testing set \n",
    "> Documentation: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "3ca436c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.477"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LinearRegression() # check the documentation to understand the default parameters\n",
    "reg.fit(X_train, y_train)\n",
    "reg_score = reg.score(X_test, y_test)\n",
    "np.round(reg_score,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92373e7b",
   "metadata": {},
   "source": [
    "**Interpret model coefficients and intercept**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "9f93ce14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  29.254, -261.706,  546.3  ,  388.398, -901.96 ,  506.763,\n",
       "        121.154,  288.035,  659.269,   41.377])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(reg.coef_,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "f66d6311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151.008"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(reg.intercept_,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a97b88",
   "metadata": {},
   "source": [
    "**Your task**: write down the linear regression model with the above coefficients and intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "e6a435a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntraget = 29.254 * age -261.706 * sex + 546.3 * bmi + 388.398 * bp - 901.96 * s1 + 506.763 * s2 + 121.154 * s3 + \\n288.035 * s4 + 659.269 * s5 + 41.377 * s6 + 151.008\\n\\n'"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "traget = 29.254 * age -261.706 * sex + 546.3 * bmi + 388.398 * bp - 901.96 * s1 + 506.763 * s2 + 121.154 * s3 + \n",
    "288.035 * s4 + 659.269 * s5 + 41.377 * s6 + 151.008\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8baf4c48",
   "metadata": {},
   "source": [
    "**Your task**: explore other parameters/attributes/methods\n",
    "- fit_intercept\n",
    "- feature_names_in_, n_features_in_\n",
    "Write your exploration code and results below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "13242258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.102\n",
      "[  46.357 -236.495  717.497  339.25  -483.675  139.746   59.973  299.417\n",
      "  500.726  209.021]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "without_intercept = LinearRegression(fit_intercept = False)\n",
    "without_intercept.fit(X_train, y_train)\n",
    "without_intercept_score = without_intercept.score(X_test, y_test)\n",
    "print(np.round(without_intercept_score,3))\n",
    "print(np.round(without_intercept.coef_,3))\n",
    "print(np.round(without_intercept.intercept_,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "d0954016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "['age' 'sex' 'bmi' 'bp' 's1' 's2' 's3' 's4' 's5' 's6']\n"
     ]
    }
   ],
   "source": [
    "print(reg.n_features_in_)\n",
    "print(reg.feature_names_in_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "c5943d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc280db1",
   "metadata": {},
   "source": [
    "### Fit and evaluate a Ridge regression model (with the same train/test data)\n",
    "> Documentation: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "71a8d3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.423"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rg_reg = Ridge()\n",
    "rg_reg.fit(X_train, y_train)\n",
    "rg_reg_score = rg_reg.score(X_test, y_test)\n",
    "np.round(rg_reg_score,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "3c783ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  45.054,  -71.947,  280.716,  195.213,   -2.229,  -17.541,\n",
       "       -148.689,  120.467,  198.614,  106.935])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(rg_reg.coef_,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "a4deaa4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151.867"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(rg_reg.intercept_,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b58d2f",
   "metadata": {},
   "source": [
    "### Your task: fit and evaluate a Lasso regression model (with the same train/test data)\n",
    "> Documentation: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "1c416398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-5 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-5 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-5 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-5 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-5 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-5 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Lasso(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Lasso<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.Lasso.html\">?<span>Documentation for Lasso</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Lasso(random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "Lasso(random_state=42)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "ls_reg = Lasso(random_state=42)\n",
    "ls_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "71c90cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.362"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate model performance\n",
    "ls_reg_score = ls_reg.score(X_test, y_test)\n",
    "np.round(ls_reg_score,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "2c5dea51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.   ,  -0.   , 443.703,  51.601,   0.   ,   0.   ,  -0.   ,\n",
       "         0.   , 201.966,   0.   ])"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Interpret model coefficients and intercept\n",
    "np.round(ls_reg.coef_,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c950962e",
   "metadata": {},
   "source": [
    "### Your task: compare the linear/ridge/lasso regression models\n",
    "- write down your code to create and display the given dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "92e90c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear</th>\n",
       "      <th>ridge</th>\n",
       "      <th>lasso</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>29.254</td>\n",
       "      <td>45.054</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>-261.706</td>\n",
       "      <td>-71.947</td>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>546.300</td>\n",
       "      <td>280.716</td>\n",
       "      <td>443.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp</th>\n",
       "      <td>388.398</td>\n",
       "      <td>195.213</td>\n",
       "      <td>51.601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s1</th>\n",
       "      <td>-901.960</td>\n",
       "      <td>-2.229</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s2</th>\n",
       "      <td>506.763</td>\n",
       "      <td>-17.541</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s3</th>\n",
       "      <td>121.154</td>\n",
       "      <td>-148.689</td>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s4</th>\n",
       "      <td>288.035</td>\n",
       "      <td>120.467</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s5</th>\n",
       "      <td>659.269</td>\n",
       "      <td>198.614</td>\n",
       "      <td>201.966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s6</th>\n",
       "      <td>41.377</td>\n",
       "      <td>106.935</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intercept</th>\n",
       "      <td>151.008</td>\n",
       "      <td>151.867</td>\n",
       "      <td>152.166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0.477</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            linear    ridge    lasso\n",
       "age         29.254   45.054    0.000\n",
       "sex       -261.706  -71.947   -0.000\n",
       "bmi        546.300  280.716  443.703\n",
       "bp         388.398  195.213   51.601\n",
       "s1        -901.960   -2.229    0.000\n",
       "s2         506.763  -17.541    0.000\n",
       "s3         121.154 -148.689   -0.000\n",
       "s4         288.035  120.467    0.000\n",
       "s5         659.269  198.614  201.966\n",
       "s6          41.377  106.935    0.000\n",
       "intercept  151.008  151.867  152.166\n",
       "score        0.477    0.423    0.362"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hint: the following dataframe shows the expected way to organize and display the information\n",
    "# make sure to: \n",
    "# - round to 3 digits after the decimal point\n",
    "# - rename the column names \n",
    "# - include intercept and score in the last two rows\n",
    "\n",
    "data = {\n",
    "    'linear': np.concatenate((np.round(reg.coef_, 3), np.array([np.round(reg.intercept_, 3), np.round(reg.score(X_test, y_test), 3)]))),\n",
    "    'ridge': np.concatenate((np.round(rg_reg.coef_, 3), np.array([np.round(rg_reg.intercept_, 3), np.round(rg_reg.score(X_test, y_test), 3)]))),\n",
    "    'lasso': np.concatenate((np.round(ls_reg.coef_, 3), np.array([np.round(ls_reg.intercept_, 3), np.round(ls_reg.score(X_test, y_test), 3)])))\n",
    "}\n",
    "\n",
    "index_names = ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6', 'intercept', 'score']\n",
    "\n",
    "df = pd.DataFrame(data, index=index_names)\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d7e638",
   "metadata": {},
   "source": [
    "**Your observations and thoughts of comparing the three models**\n",
    "- hint: connect this with what we discussed in the lectures, e.g.\n",
    "    - how does regularization affect coefficients and model performance \n",
    "    - what is the difference between ridge (L2 penalty) and Lasso (L1 penalty) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "e5e2f753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For this model, both ridge and lasso help avoid extreme coefficients to avoid overfitting problem of the model.However, model performance (score) was not enhaced by applying ridge or lasso.      For ridge, extreme coefficients have been avoided, by decreasing the coefficients close to ZERO,       but not eaqual to ZERO. However, Lasso can be useful when filtering the important attributes in the regression model,       since non-important coefficients will be descresed to ZERO.       Ridge can avoid possible model overfitting while preserve all the attributes.\n"
     ]
    }
   ],
   "source": [
    "print('For this model, both ridge and lasso help avoid extreme coefficients to avoid overfitting problem of the model.\\\n",
    "However, model performance (score) was not enhaced by applying ridge or lasso.\\\n",
    "      For ridge, extreme coefficients have been avoided, by decreasing the coefficients close to ZERO, \\\n",
    "      but not eaqual to ZERO. However, Lasso can be useful when filtering the important attributes in the regression model,\\\n",
    "       since non-important coefficients will be descresed to ZERO. \\\n",
    "      Ridge can avoid possible model overfitting while preserve all the attributes.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cca80a6",
   "metadata": {},
   "source": [
    "## Polynomial regression\n",
    "- Use the diabetes data with the same train and test set to fit several **Polynomial regression** models \n",
    "- documentation: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61aaa8fc",
   "metadata": {},
   "source": [
    "### Fit a polynomail regression model with degree=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "5c660e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(309, 66)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate the new polynomial feature matrix for the training data \n",
    "# \"fit_transform\" on the original training data\n",
    "\n",
    "poly2 = PolynomialFeatures(2)\n",
    "X_train_poly2 = poly2.fit_transform(X_train)\n",
    "X_train_poly2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "da88debb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133, 66)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate the new polynomial feature matrix for the testing data \n",
    "# only do \"transform\" on the original testing feature matrix\n",
    "# why do we do \"fit_transform\" on training data but only do \"transform\" on testing data?\n",
    "\n",
    "X_test_poly2 = poly2.transform(X_test)\n",
    "X_test_poly2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "de488def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.413"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit a regression model with the newly generated polynomial feature matrix \n",
    "# evaluate model performance \n",
    "\n",
    "poly2_reg = LinearRegression()\n",
    "poly2_reg.fit(X_train_poly2, y_train)\n",
    "poly2_score = poly2_reg.score(X_test_poly2, y_test)\n",
    "np.round(poly2_score,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72079596",
   "metadata": {},
   "source": [
    "### Your task: fit a polynomail regression model with degree=1\n",
    "- Follow the previous steps of fitting a polynomial regression model with degree=2 to **fit a new model with degree=1** (name it as $poly1\\_reg$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "e53f151c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(309, 11)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly1 = PolynomialFeatures(1)\n",
    "X_train_poly1 = poly1.fit_transform(X_train)\n",
    "X_train_poly1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "794b0562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133, 11)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_poly1 = poly1.transform(X_test)\n",
    "X_test_poly1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "3f9e86ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.477"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly1_reg = LinearRegression()\n",
    "poly1_reg.fit(X_train_poly1, y_train)\n",
    "poly1_score = poly1_reg.score(X_test_poly1, y_test)\n",
    "np.round(poly1_score,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2b9642",
   "metadata": {},
   "source": [
    "### Your task: fit a polynomail regression model with degree=3\n",
    "- Follow the previous steps of fitting a polynomial regression model with degree=2 to **fit a new model with degree=3** (name it as $poly3\\_reg$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "8760be74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(309, 286)"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly3 = PolynomialFeatures(3)\n",
    "X_train_poly3 = poly3.fit_transform(X_train)\n",
    "X_train_poly3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "8c0b9490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133, 286)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_poly3 = poly3.transform(X_test)\n",
    "X_test_poly3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "d29a3915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-92.583"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly3_reg = LinearRegression()\n",
    "poly3_reg.fit(X_train_poly3, y_train)\n",
    "poly3_score = poly3_reg.score(X_test_poly3, y_test)\n",
    "np.round(poly3_score,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc159ab",
   "metadata": {},
   "source": [
    "### Your task: compare the polynomial regression models with degree=1/2/3 and the original linear regression model\n",
    "- please write code to create and display the given data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "44f9e382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original linear</th>\n",
       "      <th>degree = 1</th>\n",
       "      <th>degree = 2</th>\n",
       "      <th>degree = 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0.477</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.413</td>\n",
       "      <td>-92.583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       original linear  degree = 1  degree = 2  degree = 3\n",
       "score            0.477       0.477       0.413     -92.583"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    'original linear': np.round(reg.score(X_test, y_test), 3),\n",
    "    'degree = 1': np.round(poly1_score,3),\n",
    "    'degree = 2': np.round(poly2_score,3),\n",
    "    'degree = 3': np.round(poly3_score,3)\n",
    "}\n",
    "\n",
    "index_names = ['score']\n",
    "\n",
    "df = pd.DataFrame(data, index=index_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051b17b2",
   "metadata": {},
   "source": [
    "### Your task: observations and thoughts of comparing the above four models\n",
    "- hint: connect this with overfitting/underfitting we discussed in class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "7aba6518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial with a degree of 1 eqauls to the orignal linear regression.\n",
      " If the original linear regression is thought be underfitting,\n",
      "       one can increase the degree to complicate the model. However,  in our case, when the polynomial degree is set to 2 or 3,\n",
      "       the model score descreases. That might be due to overfitting of model that is too complicated.\n"
     ]
    }
   ],
   "source": [
    "print('Polynomial with a degree of 1 eqauls to the orignal linear regression.\\n If the original linear regression is thought be underfitting,\\n \\\n",
    "      one can increase the degree to complicate the model. However,  in our case, when the polynomial degree is set to 2 or 3,\\n \\\n",
    "      the model score descreases. That might be due to overfitting of model that is too complicated.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e005bd8",
   "metadata": {},
   "source": [
    "### Your task: interpret the model performance wrt the task itself\n",
    "- how does each feature relate with diabetes\n",
    "- which factors contribute positively/negatively/most/least to diabetes\n",
    "- does these statistical correlations make sense from biological perspective? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "56641a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amongst the the performance of different models, we can take a look at the original linear regression model      with the highest score. We can further observe the value of the coefficients to understand the weight      of each feature or attribute that contributes to the target value. In diabetes case, amongst all the features       s1, tc, total serum cholesterol contributes most negatively to diabetes, while bmi and s5 ltg, possibly log       of serum triglycerides level contributes the most positively to diabetes. Age and glu, blood sugar level      contributes the least to diabetes.\n",
      "I think the data/regression model (especially lasso) point out several features that is highly related to      diabetes: bmi and s5 ltg, possibly log of serum triglycerides level, which relate diabetes to obesity problem.      That matches my limited biological knowledges.\n"
     ]
    }
   ],
   "source": [
    "print('Amongst the the performance of different models, we can take a look at the original linear regression model\\\n",
    "      with the highest score. We can further observe the value of the coefficients to understand the weight\\\n",
    "      of each feature or attribute that contributes to the target value. In diabetes case, amongst all the features \\\n",
    "      s1, tc, total serum cholesterol contributes most negatively to diabetes, while bmi and s5 ltg, possibly log \\\n",
    "      of serum triglycerides level contributes the most positively to diabetes. Age and glu, blood sugar level\\\n",
    "      contributes the least to diabetes.')\n",
    "print('I think the data/regression model (especially lasso) point out several features that is highly related to\\\n",
    "      diabetes: bmi and s5 ltg, possibly log of serum triglycerides level, which relate diabetes to obesity problem.\\\n",
    "      That matches my limited biological knowledges.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef82f53",
   "metadata": {},
   "source": [
    "## Linear models for classification: LogisticRegression \n",
    "In this section, we will work on a banknote authentication dataset:\n",
    "- Original data source: https://archive.ics.uci.edu/ml/datasets/banknote+authentication <br>\n",
    "\n",
    "This dataset contains n = 1372 images of genuine and forged banknote-like specimens. Each image is represented by four features extracted from Wavelet Transform tool: \n",
    "    1. variance (continuous) \n",
    "    2. skewness (continuous)\n",
    "    3. curtosis (continuous)\n",
    "    4. entropy of image (continuous)\n",
    "\n",
    "And each image has a binary label of 0/1 indicating whether the banknote is forged or genuine.\n",
    "\n",
    "We will fit several logistic regression models with different parameter settings to analyze this dataset: \n",
    "The steps include:\n",
    "1. Basic data exploration:\n",
    "    > what does the data look like (#samples, #features) <br>\n",
    "    > the feature matrix and description of each feature <br>\n",
    "    > the target values <br>\n",
    "    \n",
    "2. Prepare data for model training and testing <br>\n",
    "\n",
    "3. Fit different logistic regression models (vary by parameter settings) on the training set and evaluate model performance on the testing set <br>\n",
    "\n",
    "4. Compare and understand model performance through interpreting coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "574468b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "cf817f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# please change to your file path\n",
    "df_data = pickle.load(open('./banknote_authentication_dataframe.pickle','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a442ec9",
   "metadata": {},
   "source": [
    "### Basic dataset exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "a876742b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.66610</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.16740</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.63830</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.52280</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.45520</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>0.40614</td>\n",
       "      <td>1.34920</td>\n",
       "      <td>-1.4501</td>\n",
       "      <td>-0.55949</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>-1.38870</td>\n",
       "      <td>-4.87730</td>\n",
       "      <td>6.4774</td>\n",
       "      <td>0.34179</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>-3.75030</td>\n",
       "      <td>-13.45860</td>\n",
       "      <td>17.5932</td>\n",
       "      <td>-2.77710</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>-3.56370</td>\n",
       "      <td>-8.38270</td>\n",
       "      <td>12.3930</td>\n",
       "      <td>-1.28230</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>-2.54190</td>\n",
       "      <td>-0.65804</td>\n",
       "      <td>2.6842</td>\n",
       "      <td>1.19520</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1372 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      variance  skewness  curtosis  entropy  class\n",
       "0      3.62160   8.66610   -2.8073 -0.44699    0.0\n",
       "1      4.54590   8.16740   -2.4586 -1.46210    0.0\n",
       "2      3.86600  -2.63830    1.9242  0.10645    0.0\n",
       "3      3.45660   9.52280   -4.0112 -3.59440    0.0\n",
       "4      0.32924  -4.45520    4.5718 -0.98880    0.0\n",
       "...        ...       ...       ...      ...    ...\n",
       "1367   0.40614   1.34920   -1.4501 -0.55949    1.0\n",
       "1368  -1.38870  -4.87730    6.4774  0.34179    1.0\n",
       "1369  -3.75030 -13.45860   17.5932 -2.77710    1.0\n",
       "1370  -3.56370  -8.38270   12.3930 -1.28230    1.0\n",
       "1371  -2.54190  -0.65804    2.6842  1.19520    1.0\n",
       "\n",
       "[1372 rows x 5 columns]"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the dataset\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "222a148c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.433735</td>\n",
       "      <td>1.922353</td>\n",
       "      <td>1.397627</td>\n",
       "      <td>-1.191657</td>\n",
       "      <td>0.444606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.842763</td>\n",
       "      <td>5.869047</td>\n",
       "      <td>4.310030</td>\n",
       "      <td>2.101013</td>\n",
       "      <td>0.497103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-7.042100</td>\n",
       "      <td>-13.773100</td>\n",
       "      <td>-5.286100</td>\n",
       "      <td>-8.548200</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.773000</td>\n",
       "      <td>-1.708200</td>\n",
       "      <td>-1.574975</td>\n",
       "      <td>-2.413450</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.496180</td>\n",
       "      <td>2.319650</td>\n",
       "      <td>0.616630</td>\n",
       "      <td>-0.586650</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.821475</td>\n",
       "      <td>6.814625</td>\n",
       "      <td>3.179250</td>\n",
       "      <td>0.394810</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.824800</td>\n",
       "      <td>12.951600</td>\n",
       "      <td>17.927400</td>\n",
       "      <td>2.449500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          variance     skewness     curtosis      entropy        class\n",
       "count  1372.000000  1372.000000  1372.000000  1372.000000  1372.000000\n",
       "mean      0.433735     1.922353     1.397627    -1.191657     0.444606\n",
       "std       2.842763     5.869047     4.310030     2.101013     0.497103\n",
       "min      -7.042100   -13.773100    -5.286100    -8.548200     0.000000\n",
       "25%      -1.773000    -1.708200    -1.574975    -2.413450     0.000000\n",
       "50%       0.496180     2.319650     0.616630    -0.586650     0.000000\n",
       "75%       2.821475     6.814625     3.179250     0.394810     1.000000\n",
       "max       6.824800    12.951600    17.927400     2.449500     1.000000"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describe the data \n",
    "df_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcbafff",
   "metadata": {},
   "source": [
    "### Prepara data for model training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "1fbc714a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1372, 4), (1372,), Counter({0.0: 762, 1.0: 610}))"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = ['variance','skewness','curtosis','entropy']\n",
    "\n",
    "# Construct feature matrix from the data frame\n",
    "X_data = df_data[feature_names]\n",
    "y_data = df_data['class']\n",
    "X_data.shape, y_data.shape, Counter(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "98dc3fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into 70% training and 30% testing using train_test_split()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3bb9b2",
   "metadata": {},
   "source": [
    "### Fit LogisticRegression models with different parameter settings\n",
    "- L1 VS L2 penalty\n",
    "- C values (inverse of regularization strength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "2e206acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0, solver='liblinear', penalty='l1', C=1.0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "cb8b57ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9878640776699029"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "0baa21e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0.])"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "2525662f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.   , 0.   ],\n",
       "       [0.982, 0.018],\n",
       "       [0.996, 0.004]])"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(clf.predict_proba(X_test[:3]),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8ff19c",
   "metadata": {},
   "source": [
    "**Your task**: explore at least one different set of parameters to re-fit the model: solver, penalty, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "598e50e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9878640776699029"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_l2 = LogisticRegression(random_state=0, solver='liblinear', penalty='l2', C=1.0).fit(X_train, y_train)\n",
    "clf_l2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "aa54baff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0.])"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_l2.predict(X_test[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "fdfa9b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.   , 0.   ],\n",
       "       [0.963, 0.037],\n",
       "       [0.987, 0.013]])"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(clf_l2.predict_proba(X_test[:3]),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "5b597300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9902912621359223"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_l2_lite = LogisticRegression(random_state=0, solver='liblinear', penalty='l2', C=100).fit(X_train, y_train)\n",
    "clf_l2_lite.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "3f4b8297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.   , 0.   ],\n",
       "       [0.999, 0.001],\n",
       "       [1.   , 0.   ]])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(clf_l2_lite.predict_proba(X_test[:3]),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c5d0d1",
   "metadata": {},
   "source": [
    "### Compare model performance with different c values and different penalties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "9160ab01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_c(X_train, y_train, X_test, y_test, p):\n",
    "    \"\"\"\n",
    "    X_train/test: 2D feature matrix of training/testing data\n",
    "    y_train/test: 1D array of training/testing labels\n",
    "    p: the penalty parameter setting in LogisticRegression\n",
    "    \n",
    "    return: \n",
    "        a list of classifiers fitted with different c values\n",
    "        a dataframe that is shown in the running example below\n",
    "    \"\"\"\n",
    "     \n",
    "    # set the model parameter c to different values and train the model \n",
    "    # for c in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    #    fit a LogisticRegression model with: the current c value, the given penalty p, set random_state=42, max_iter=1000, solver='liblinear', and use default setting for other parameters\n",
    "    #    test and record the model performance \n",
    "    #    get the statistical information about the model coefficients: \n",
    "    #        min: minimum coefficient\n",
    "    #        max: minimum coefficient\n",
    "    #        mean(abs(coef)): average over the absolute coefficient values\n",
    "    #        n_zero: number of coefficients equal to zero \n",
    "    \n",
    "    ### Your code starts from here \n",
    "\n",
    "    data = []\n",
    "\n",
    "    for c in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "        clf = LogisticRegression(random_state=0, solver='liblinear', penalty=p, C=c).fit(X_train, y_train)\n",
    "        min = np.round(np.min(clf.coef_),3)\n",
    "        max = np.round(np.max(clf.coef_),3)\n",
    "        mean = np.round(np.mean(np.abs(clf.coef_)),3)\n",
    "        n_zero = np.count_nonzero(clf.coef_ == 0)\n",
    "        score = np.round(clf.score(X_test, y_test),3)\n",
    "        data.append([c, min, max, mean, n_zero, score])\n",
    "    \n",
    "    index_names = ['c', 'min', 'max', 'mean_abs', 'n_zero', 'test_score']\n",
    "    df = pd.DataFrame(data, columns=index_names)\n",
    "\n",
    "    return clf, df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "d7fb1b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean_abs</th>\n",
       "      <th>n_zero</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.357</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0</td>\n",
       "      <td>0.922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.861</td>\n",
       "      <td>-0.173</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>-1.581</td>\n",
       "      <td>-0.163</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0</td>\n",
       "      <td>0.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>-2.835</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>1.645</td>\n",
       "      <td>0</td>\n",
       "      <td>0.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>-5.171</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>2.937</td>\n",
       "      <td>0</td>\n",
       "      <td>0.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.000</td>\n",
       "      <td>-7.648</td>\n",
       "      <td>-0.438</td>\n",
       "      <td>4.297</td>\n",
       "      <td>0</td>\n",
       "      <td>0.990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         c    min    max  mean_abs  n_zero  test_score\n",
       "0    0.001 -0.357 -0.074     0.190       0       0.922\n",
       "1    0.010 -0.861 -0.173     0.485       0       0.973\n",
       "2    0.100 -1.581 -0.163     0.915       0       0.988\n",
       "3    1.000 -2.835 -0.166     1.645       0       0.988\n",
       "4   10.000 -5.171 -0.290     2.937       0       0.988\n",
       "5  100.000 -7.648 -0.438     4.297       0       0.990"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running example\n",
    "l2_clfs, c_effect_l2 = compare_c(X_train, y_train, X_test, y_test, p='l2')\n",
    "c_effect_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "7bd278a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean_abs</th>\n",
       "      <th>n_zero</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>3</td>\n",
       "      <td>0.624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.807</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.328</td>\n",
       "      <td>1</td>\n",
       "      <td>0.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>-1.749</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.935</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>-3.852</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>2.172</td>\n",
       "      <td>0</td>\n",
       "      <td>0.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>-7.081</td>\n",
       "      <td>-0.387</td>\n",
       "      <td>3.977</td>\n",
       "      <td>0</td>\n",
       "      <td>0.990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.000</td>\n",
       "      <td>-8.179</td>\n",
       "      <td>-0.463</td>\n",
       "      <td>4.586</td>\n",
       "      <td>0</td>\n",
       "      <td>0.990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         c    min    max  mean_abs  n_zero  test_score\n",
       "0    0.001 -0.042  0.000     0.010       3       0.624\n",
       "1    0.010 -0.807  0.000     0.328       1       0.917\n",
       "2    0.100 -1.749  0.000     0.935       1       0.988\n",
       "3    1.000 -3.852 -0.133     2.172       0       0.988\n",
       "4   10.000 -7.081 -0.387     3.977       0       0.990\n",
       "5  100.000 -8.179 -0.463     4.586       0       0.990"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running example\n",
    "l1_clfs, c_effect_l1 = compare_c(X_train, y_train, X_test, y_test, p='l1')\n",
    "c_effect_l1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934a8855",
   "metadata": {},
   "source": [
    "**Your thoughts and observations:** \n",
    "  - explain model performance from the perspective of under-fitting VS over-fitting\n",
    "  - compare the two tables and indicate the difference between L1 and L2 penalty\n",
    "  - how does c affect coefficients and model performance in each table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "2c6fd232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When one increases the value of C, the regularization of the model decreases,       which makes the model more complicated. In this case, the test score increases,      which means the model with samll C value, might encounter underfitting problems.\n",
      "There are zero values in the coefficients of L1, which means some features      have been ignored in L1, while all the features in L2 are still preserved.       L2 scores are pretty constantly good amongst different C values, which means      the regularization strength does not influence the result too much in L2.       However when some non-significant features removed in L1 and complexity of       the model is reduced, underfitting problem shows up.\n"
     ]
    }
   ],
   "source": [
    "print('When one increases the value of C, the regularization of the model decreases,\\\n",
    "       which makes the model more complicated. In this case, the test score increases,\\\n",
    "      which means the model with samll C value, might encounter underfitting problems.')\n",
    "print('There are zero values in the coefficients of L1, which means some features\\\n",
    "      have been ignored in L1, while all the features in L2 are still preserved. \\\n",
    "      L2 scores are pretty constantly good amongst different C values, which means\\\n",
    "      the regularization strength does not influence the result too much in L2. \\\n",
    "      However when some non-significant features removed in L1 and complexity of \\\n",
    "      the model is reduced, underfitting problem shows up.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd39d68",
   "metadata": {},
   "source": [
    "### Interpret the model performance wrt the banknote authentication task\n",
    "- how does each feature relate with the identification of genuine and forged banknote\n",
    "- does these statistical correlations make sense from the perspective of image recognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "a0440979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWith the increase of all of the four features, the probability of the ceck being \\ngenuine descreased. due to the negative coefficients. However, entropy is the least\\nrelated feature amongst the four. It makes sense in image recognition, because the\\nincreased variance/skewness/curtosis in an image might mean, the banknote does not \\nhave a high quality. It might be forged.\\n\\n'"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(clf.coef_, 3)\n",
    "#variance\tskewness\tcurtosis\tentropy\n",
    "\n",
    "'''\n",
    "With the increase of all of the four features, the probability of the ceck being \n",
    "genuine descreased. due to the negative coefficients. However, entropy is the least\n",
    "related feature amongst the four. It makes sense in image recognition, because the\n",
    "increased variance/skewness/curtosis in an image might mean, the banknote does not \n",
    "have a high quality. It might be forged.\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bcb91b",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Congratulations for completing this exercise! In this notebook, with hands-on practice of linear models for regression and classification tasks, we gain deep understanding of:\n",
    "- overfitting VS underfitting\n",
    "- difference between l1 and l2 regularizations\n",
    "- the effect of regularization strength on model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327df471",
   "metadata": {},
   "source": [
    "## Which part(s) you find most interesting/chanlleging?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "1638e4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I think the overall implementation and the testing scores process of models with \n",
      "different parameters have been quite interesting to me. Also interpreting the result\n",
      "using real-world cases, give me good practice in data-driven storytelling.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('''\n",
    "I think the overall implementation and the testing scores process of models with \n",
    "different parameters have been quite interesting to me. Also interpreting the result\n",
    "using real-world cases, give me good practice in data-driven storytelling.\n",
    "\n",
    "''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
